{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bashah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bashah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\bashah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# User Case - implementation\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# step 1 - convolution \n",
    "# this is input layer\n",
    "classifier.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation= 'relu'))\n",
    "\n",
    "# adding a second convolution layer\n",
    "# hidden layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation= 'relu'))\n",
    "# this is wonderful concept of mapping and reducing, 64, 64, 3 to 2,2 dimensional\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening 2 dimensional image into two dimensional image\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Full connection \n",
    "\n",
    "# bringing straight what outcomes from relu and then passing it to a different function sigmoid for exact 0/1 output as dog or cat\n",
    "\n",
    "classifier.add(Dense(units= 128, activation= 'relu')) # here 128 is used because we have used 64/64 image, we can twikle it and see different results haru\n",
    "classifier.add(Dense(units= 1, activation = 'sigmoid')) # this will yield cat or not, 1 is for cat and 0 for dog\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bashah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compiling the CNN\n",
    "# optimizer is reverse propagation\n",
    "# adam is most commoinly used in big data, others are \n",
    "# loss and metric are common and need to be learned from keras to know more, standard deviation \n",
    "\n",
    "classifier.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2 - fitting CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale= 1./255, \n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range= 0.2,\n",
    "                                   horizontal_flip= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\bashah\\OneDrive - Ncell Axiata Limited\\ncell\\Development\\AI-based-customer-sentiment-analysis\\Resources\\training_set',\n",
    "                                                 target_size= (64,64),\n",
    "                                                 batch_size= 32,\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale= 1./255,\n",
    "                                  shear_range= 0.2,\n",
    "                                  zoom_range= 0.2,\n",
    "                                  horizontal_flip= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(r'C:\\Users\\bashah\\OneDrive - Ncell Axiata Limited\\ncell\\Development\\AI-based-customer-sentiment-analysis\\Resources\\test_set',\n",
    "                                            target_size= (64,64),\n",
    "                                            batch_size= 32,\n",
    "                                            class_mode= 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.4901 - accuracy: 0.7610 - val_loss: 0.4915 - val_accuracy: 0.7695\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 53s 211ms/step - loss: 0.4696 - accuracy: 0.7746 - val_loss: 0.5032 - val_accuracy: 0.7595\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 47s 189ms/step - loss: 0.4514 - accuracy: 0.7860 - val_loss: 0.4972 - val_accuracy: 0.7640\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 55s 222ms/step - loss: 0.4247 - accuracy: 0.8029 - val_loss: 0.5013 - val_accuracy: 0.7690\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 57s 229ms/step - loss: 0.4002 - accuracy: 0.8163 - val_loss: 0.4956 - val_accuracy: 0.7745\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = len(training_set)\n",
    "history = classifier.fit(\n",
    "    training_set,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=250,  # sample used in each iteration\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "This is a Dog\n"
     ]
    }
   ],
   "source": [
    "# making new prediction to identify if its dog or cat\n",
    "import numpy as np \n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(r'C:\\Users\\bashah\\OneDrive - Ncell Axiata Limited\\ncell\\Development\\AI-based-customer-sentiment-analysis\\Resources\\single_prediction\\b.jpg', target_size = (64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'This is a Dog'\n",
    "    \n",
    "else:\n",
    "    prediction = 'This is a bloody cat'\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
